{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"filter_le",
				"filter_length+2:end"
			],
			[
				"these",
				"thesepoints"
			],
			[
				"diag",
				"diagnostics2"
			],
			[
				"filter",
				"filter_length"
			],
			[
				"marker",
				"marker_size2"
			],
			[
				"filter_",
				"filter_length"
			],
			[
				"Chich",
				"Chichilnisky"
			],
			[
				"mark",
				"marker_size"
			],
			[
				"Chci",
				"Chichlinsky's"
			],
			[
				"Fit",
				"FitFilter2Data"
			],
			[
				"shif",
				"shift_input"
			],
			[
				"Line",
				"LineWidth"
			],
			[
				"LNFit",
				"LNFitQualityLow"
			],
			[
				"high",
				"high_slopes"
			],
			[
				"Slope",
				"SlopeRatios"
			],
			[
				"output",
				"output_data"
			],
			[
				"summ",
				"summ_fig"
			],
			[
				"model",
				"model_values"
			],
			[
				"histo",
				"history_lengths"
			],
			[
				"low_s",
				"low_slopes_err"
			],
			[
				"Shelf",
				"ShelfFilesList"
			],
			[
				"XTick",
				"XTickLabel"
			],
			[
				"Odour",
				"OdourDuration"
			],
			[
				"File",
				"FileName2GenoDate"
			],
			[
				"V",
				"Valve"
			],
			[
				"Th",
				"Thrusto"
			],
			[
				"Cluster",
				"ClusterDataButton"
			],
			[
				"Thru",
				"Thrustc"
			],
			[
				"Thr",
				"Thrusto"
			],
			[
				"THR",
				"Thrusto"
			],
			[
				"WB",
				"WBFc"
			],
			[
				"WBF",
				"WBFo"
			],
			[
				"Tri",
				"TrialVariabilityCallback"
			],
			[
				"font-",
				"font-weight"
			],
			[
				"background",
				"background	background: color image repeat attachment position"
			]
		]
	},
	"buffers":
	[
		{
			"contents": "%% Dynamical Adaptation in ORNs \n% Do ORNs exhibit fast adaptation to a flickering stimulus? Can a simple dynamical adaptation model predict ORN responses to flickering inputs? Here, I take data from Carlotta's random stimulus experiments and first check how well a simple linear prediction from the stimulus compares to the data. Then, I study how the instantaneous gain of the actual ORN response w.r.t to the predicted ORN response varies with time, and try to find a objective filter from the stimulus to this instantaneous gain to correct for systematic errors in the linear prediction.  \n\n%%\n\n% parameters to tune for figure display\nfont_size = 20;\nmarker_size = 10;\nmarker_size2 = 20;\n\n%% Data Visualisation \n% Data from this file will be used for this analysis.\n\nfilename = '/data/random-stim/final_2011_06_14_ab3A_1o3ol3X-3_20ml_30sec_30ms_rand.mat';\ndisp(filename)\n\n%%\n% Here, data from simultaneous measurements of the stimulus and from the ORN is shown. The top row shows the valve command signal (a binary signal, high means valve is open). The middle row shows the simultaneous measurement of the odour stimulus with a PID, and the bottom row shows the instantaneous firing rate of the ORN recorded from. \n\ncrop_traces = 0;\n% grab data\nif ~(exist('PID') == 1)\n	crop_traces = 1;\n	[PID time f fs Valve ntrials] = PrepData2(filename);\n\n	% make all vectors consistent\n	PID = PID(:);\n	time = time(:);\n	f = f(:);\n	fs = fs(:);\n	Valve = Valve(:);\n\n	% detrend PID\n	ptrend = fit(time,PID,'Poly1'); \n	PID = PID - (ptrend(time) - mean(ptrend(time)));\n\n	% detrend f\n	ptrend = fit(time,f,'Poly1'); \n	f = f - (ptrend(time) - mean(ptrend(time)));\n\n	clear ptrend\nend\n\n% plot the data\nfigure('outerposition',[0 0 1000 700],'PaperUnits','points','PaperSize',[1000 700]); hold on\nsubplot(3,1,1), hold on\nplot(time,Valve,'LineWidth',2)\nset(gca,'box','on','LineWidth',2,'XLim',[18 22],'YLim',[-0.1 1.1])\nylabel('stimulus')\n\nsubplot(3,1,2), hold on\nplot(time,PID,'LineWidth',2)\nset(gca,'box','on','LineWidth',2,'XLim',[18 22])\nylabel('PID (a.u.)')\n\nsubplot(3,1,3), hold on\nplot(time,f,'LineWidth',2)\nset(gca,'box','on','LineWidth',2,'XLim',[18 22])\nxlabel('Time (s)')\nylabel('Firing Rate (Hz)')\n\n%% \n% The odour used, the neuron recorded from and the correlation time of the flickering stimulus are in the file name displayed above the plot.\n\n%% Filter Extraction \n% Details about the filter extraction, regularisation methods, and validation with synthetic and real data is listed in (FilterExtraction.pdf). Here, we calculate the best filter (scaled to ensure that gain = 1) using techniques described in that document from the PID (left) and from the Valve (right).\n\n% shift input, black magic. why are we shifting input? no clue. but this is what Carlotta does. is there a lag between the to traces? why is it this? \nshift_input = 33;\nif crop_traces\n	time = time(1:end-shift_input+1);\n	Valve = Valve(1:end-shift_input+1);\n	PID = PID(shift_input:end);\n	f = f(1:end-shift_input+1);\n	fs = fs(1:end-shift_input+1);\nend\n\n\n% compute filter\nfilter_length = 333;\nfiltertime = 0:mean(diff(time)):filter_length*mean(diff(time)); % this is the x axis for the \n\nif ~(exist('K') == 1)\n	[K diagnostics] = FindBestFilter(PID,f,filter_length);\n	K = K*diagnostics.slope(diagnostics.bestfilter);\nend\n\nif ~(exist('K_Valve') == 1)\n	[K_Valve diagnostics_valve] = FindBestFilter(Valve,f,filter_length);\n	K_Valve = K_Valve*diagnostics_valve.slope(diagnostics_valve.bestfilter);\nend\n\n% plot\nfigure('outerposition',[0 0 700 350],'PaperUnits','points','PaperSize',[800 350]); hold on\nsubplot(1,2,1), hold on\nplot(filtertime,K,'LineWidth',2)\nset(gca,'box','on','LineWidth',2,'FontSize',font_size)\nxlabel('Lag (s)','FontSize',20)\nylabel('Filter Amplitude (Hz)','FontSize',font_size)\ntitle('PID > f','FontSize',font_size)\n\nsubplot(1,2,2), hold on\nplot(filtertime,K_Valve,'LineWidth',2)\nset(gca,'box','on','LineWidth',2,'FontSize',font_size)\nxlabel('Lag (s)','FontSize',20)\nylabel('Filter Amplitude (Hz)','FontSize',font_size)\ntitle('Valve > f','FontSize',font_size)\n\n%%\n% The variation of filter shape with regularisation parameter for the PID > f filter is shown below:\n\nPlotFilterDiagnostics2(diagnostics,marker_size,marker_size2,font_size,'PID > f')\n\n%%\n% The variation of filter shape with regularisation parameter for the Valve > f filter is shown below:\n\nPlotFilterDiagnostics2(diagnostics_valve,marker_size,marker_size2,font_size,'Valve > f')\n\n\n\n%%\n% The convolution of this filter with the input (PID) gives a prediction of the output. In the figure below, the data is shown in black, and the prediction from the PID filter is shown in blue and the prediction from the Valve filter is shown in red. Note that sometimes the prediction can be below zero, which doesn't mean anything physical (firing rate cannot be < 0). \n\nfigure('outerposition',[0 0 800 500],'PaperUnits','points','PaperSize',[800 500]); hold on\nfp = filter(K,1,PID-mean(PID)) + mean(f);\n% censor initial prediction\nfp(1:filter_length+1)=NaN;\n\nfp_valve = filter(K_Valve,1,Valve-mean(Valve))+mean(f);\n% censor initial prediction\nfp_valve(1:filter_length+1)=NaN;\n\nplot(time,f,'k','LineWidth',2)\nplot(time,fp,'b','LineWidth',2)\nplot(time,fp_valve,'r','LineWidth',2)\nset(gca,'XLim',[mean(time)-2 mean(time)+2],'box','on','LineWidth',2,'FontSize',font_size)\nxlabel('Time (s)','FontSize',20)\nylabel('Firing Rate (Hz)','FontSize',font_size)\ntitle('Comparison of data and prediction.')\nlegend Data PID Valve\n\n\n%% Analysis of Linear Prediction - Which input predicts output better?\n% The measurement of the stimulus should help us predict the response of the neuron better than just the valve control signal, as we now capture the fast fluctuations of the odour stimulus as it reaches the ORN. Thus, a prediction of ORN firing response from the PID signal should be better than a prediction of the ORN firing response from the valve signal. \n\n%%\n% The r-square (coefficient of determination) of the PID>f prediction is:\ndisp(rsquare(f(filter_length+2:end),fp(filter_length+2:end)))\n\n%%\n% The r-square (coefficient of determination) of the Valve>f prediction is:\ndisp(rsquare(f(filter_length+2:end),fp_valve(filter_length+2:end)))\n\n\n%% Analysis of Linear Prediction - Linearity of Prediction \n% For a linear filter calculated from the data, a plot of the actual response to the predicted response can be fit with a line of slope 1. Here the actual firing rate is plotted on the X axis and the firing rate predicted from the linear filter is plotted on the Y axis. \n\n\n\nfigure('outerposition',[0 0 800 350],'PaperUnits','points','PaperSize',[800 350]); hold on\nsubplot(1,2,1), hold on\nplot(fp,f,'.','MarkerSize',marker_size)\nset(gca,'LineWidth',2,'FontSize',20,'box','on')\nset(gca,'XLim',[min([fp; f]) max([fp; f])],'YLim',[min([fp; f]) max([fp; f])])\naxis square\nylabel('Actual Firing rate (Hz)','FontSize',20)\nxlabel('Linear Predictionf Firing rate (Hz)','FontSize',20)\n[fall ~] = fit(fp(filter_length+2:end),f(filter_length+2:end),'Poly1');\nplot(fall(min(f):1:max(f)),min(f):1:max(f),'k','LineWidth',2)\ntitle('PID > f','FontSize',font_size)\n\nsubplot(1,2,2), hold on\nplot(fp_valve,f,'.','MarkerSize',marker_size)\nset(gca,'LineWidth',2,'FontSize',20,'box','on')\nset(gca,'XLim',[min([fp_valve; f]) max([fp_valve; f])],'YLim',[min([fp_valve; f]) max([fp_valve; f])])\naxis square\nxlabel('Linear Prediction Firing rate (Hz)','FontSize',20)\n[fall2 ~] = fit(fp_valve(filter_length+2:end),f(filter_length+2:end),'Poly1');\nplot(fall2(min(f):1:max(f)),min(f):1:max(f),'k','LineWidth',2)\ntitle('Valve > f','FontSize',font_size)\n\n%% \n% The line is a best fit to all the data. The slope of the best fit line for the prediction from PID is: \ndisp(fall.p1)\n\n%% \n% The line is a best fit to all the data. The slope of the best fit line for the prediction from the valve is: \ndisp(fall2.p1)\n\n\n%% Analysis of Linear Prediction - Response to High and Low Stimuli\n% How does the response of the ORN differ for high and low stimuli? Specifically, does the neuron display the characteristics of fast adaptation to this flickering stimulus? \n\n%%\n% To look at this, we calculate the mean average stimulus over some window history length for every time point _t_, for various different window history lengths. The effect of this operation is shown in the figure below, where the legend refers to the history window in ms. \nhistory_lengths = [30 102 150 201 300 402 501 600 801 1002];\nhl = history_lengths/3; % history lengths better be divisible by 3!\nshat = NaN(length(hl),length(PID));\nfor i = 1:length(hl)\n	shat(i,:) = filter(ones(1,hl(i))/hl(i),1,PID);\n	shat(i,1:hl(i)) = NaN;\nend\nfigure('outerposition',[10 10 1000 700],'PaperUnits','points','PaperSize',[1000 700]); hold on\nplot(time,PID,'k','LineWidth',2)\nplot(time,shat(1,:),'r','LineWidth',2)\nplot(time,shat(5,:),'b','LineWidth',3)\nplot(time,shat(10,:),'g','LineWidth',4)\nset(gca,'XLim',[mean(time)-2 mean(time)+2],'LineWidth',2,'box','on','FontSize',font_size)\nlegend 0ms 30ms 300ms 1002ms \nxlabel('Time (s)','FontSize',font_size)\nylabel('PID (a.u.)','FontSize',font_size)\n%%\n% Now, we separate neuron responses and linear prediction at times when the mean average stimulus is in the lowest 10% or the highest 10%. These points are marked either green (lowest 10%) or red (or highest 10%) in the figures below, while all the data is plotted in grey. Lines are fit to each of these clouds of points, and the slopes (representing the instantaneous gain) is calculated from these lines. The _y_ axis is the actual firing rate, while the _x_ axis is the predicted firing rate. In this analysis the prediction from the PID is used.\n\n% make data vectors\nlow_slopes = NaN*history_lengths;\nlow_slopes_err = NaN*history_lengths;\nhigh_slopes = NaN*history_lengths;\nhigh_slopes_err = NaN*history_lengths;\nlow_gof = NaN*history_lengths;\nhigh_gof = NaN*history_lengths;\n\n% calculate the slopes for all points\n[fall gof] = fit(fp(filter_length+2:end),f(filter_length+2:end),'Poly1');\nall_gof = gof.rsquare;\ner = confint(fall);\nall_slopes_err=fall.p1-er(1,1);\nall_slopes = fall.p1;\noutput_data.all_slopes = all_slopes;\n\nf3= figure('outerposition',[0 0 1000 600],'PaperUnits','points','PaperSize',[1000 600]); hold on\nfor i = 1:length(history_lengths)\n\n	figure(f3), hold on\n	subplot(2,5,i), hold on\n\n	this_shat = shat(i,:);\n	this_shat(1:hl(i)) = Inf; % the initial segment where we can't estimate shat is excluded\n	[sorted_shat idx] = sort(this_shat,'ascend');\n	f_low = f(idx(1:floor(length(PID)/10)));\n	fp_low = fp(idx(1:floor(length(PID)/10)));\n\n	this_shat(1:hl(i)) = -Inf;\n	[sorted_shat idx] = sort(this_shat,'descend');\n	f_high = f(idx(1:floor(length(PID)/10)));\n	fp_high = fp(idx(1:floor(length(PID)/10)));\n\n	plot(fp,f,'.','MarkerSize',marker_size,'MarkerFaceColor',[0.7 0.7 0.7],'MarkerEdgeColor',[0.7 0.7 0.7])\n	plot(fp_low,f_low,'.','MarkerSize',marker_size,'MarkerFaceColor',[0.5 1 0.5],'MarkerEdgeColor',[0.5 1 0.5])\n	plot(fp_high,f_high,'.','MarkerSize',marker_size,'MarkerFaceColor',[1 0.5 0.5],'MarkerEdgeColor',[1 0.5 0.5])\n	set(gca,'LineWidth',2,'box','on','FontSize',font_size)\n	set(gca,'XLim',[min(f)-10,max(f)+10],'YLim',[min(f)-10,max(f)+10])\n	axis square\n	title(strcat(mat2str(history_lengths(i)),'ms'))\n\n	if i == 6\n		xlabel('Linear Prediction (Hz)','FontSize',16)\n		ylabel('Neuron Response (Hz)','FontSize',16)\n	end\n\n\n	% remove NaN values\n	f_high(isnan(fp_high)) = [];\n	fp_high(isnan(fp_high)) = [];\n	f_low(isnan(fp_low)) = [];\n	fp_low(isnan(fp_low)) = [];\n\n	% fit lines\n	[flow gof] = fit(fp_low,f_low,'Poly1');\n	low_gof(i) = gof.rsquare;\n	er = confint(flow);\n	low_slopes_err(i)=flow.p1-er(1,1);\n	low_slopes(i) = flow.p1;\n\n	[fhigh gof] = fit(fp_high,f_high,'Poly1');\n	high_gof(i) =  gof.rsquare;\n	er = confint(fhigh);\n	high_slopes_err(i)=fhigh.p1-er(1,1);\n	high_slopes(i) = fhigh.p1;\n\n\n	% plot the best fit lines\n	plot(min(f):max(f),fall(min(f):max(f)),'Color',[0.5 0.5 0.5],'LineWidth',2)\n	plot(min(f_low):max(f_low),flow(min(f_low):max(f_low)),'g','LineWidth',2)\n	plot(min(f_high):max(f_high),fhigh(min(f_high):max(f_high)),'r','LineWidth',2)\n\n\nend\n\n\n\n%%\n% The following plot shows how the slope of the lines of best fit, or the instantaneous gains, varies with the history length. The plot on the right shows the goodness of fit for each fit, indicating the regions where the fit is meaningful.\n\n% plot to summary figure\nfigure('outerposition',[10 10 1000 500],'PaperUnits','points','PaperSize',[1000 700]); hold on\nsubplot(1,2,1), hold on\nplot(history_lengths,all_slopes*ones(1,length(history_lengths)),'k','LineWidth',2), hold on\nerrorbar(history_lengths,low_slopes,low_slopes_err,'g','LineWidth',2), hold on\nerrorbar(history_lengths,high_slopes,high_slopes_err,'r','LineWidth',2)\nset(gca,'LineWidth',2,'FontSize',20,'box','on','XLim',[0 max(history_lengths)])\nxlabel('History Length (ms)','FontSize',20)\nylabel('Slope data/prediction (gain)','FontSize',20)\n\nsubplot(1,2,2), hold on\nplot(history_lengths,low_gof,'g','LineWidth',2),hold on\nplot(history_lengths,high_gof,'r','LineWidth',2)\nxlabel('History Length (ms)','FontSize',20)\nylabel('Goodness of Fit, rsquare','FontSize',20)\nset(gca,'LineWidth',2,'FontSize',20,'box','on','YLim',[0 1.1],'XLim',[0 max(history_lengths)])\n\noutput_data.high_slopes = high_slopes;\noutput_data.high_slopes_err = high_slopes_err;\noutput_data.low_slopes = low_slopes;\noutput_data.low_slopes_err = low_slopes_err;\noutput_data.low_gof = low_gof;\noutput_data.high_gof = high_gof;\n\n%% Analysis of Linear Prediction - Filter Variation (to be done)\n% We have segmented the entire data set based on when the stimulus, averaged in some way over the past, into high and low. Here, I will calculate filters for each of these subsets. \n\n%% Analysis of Linear Prediction - Does adding another linear filter improve prediction?\n% An ideal linear filter should capture all the linear variation in the data. This means that if one were to construct a vector of residuals, a linear filter would be unable to predict the residuals from the data, and would lead to no improvement on the original filter. Is this true? \n\n%%\n% First, we construct a vector of residuals by subtracting the linear prediction from the data.\nres = f - fp;\nfigure('outerposition',[0 0 800 350],'PaperUnits','points','PaperSize',[800 350]); hold on\nsubplot(2,1,1), hold on\nplot(time,res,'k','LineWidth',2)\nset(gca,'XLim',[mean(time)-1 mean(time)+2],'FontSize',font_size,'LineWidth',2,'box','on')\nylabel('Residuals','FontSize',font_size)\nsubplot(2,1,2), hold on\nplot(time,PID,'k','LineWidth',2)\nylabel('PID','FontSize',font_size)\nset(gca,'XLim',[mean(time)-1 mean(time)+2],'FontSize',font_size,'LineWidth',2,'box','on')\nxlabel('Time (s)','FontSize',font_size)\n\n%%\n% we then construct a filter from the PID to these residuals to try to predict the residuals.\n[Kres ,diagnostics_res] = FindBestFilter(PID(filter_length+2:end),res(filter_length+2:end),filter_length);\n\nfigure('outerposition',[0 0 400 400],'PaperUnits','points','PaperSize',[800 400]); hold on\nplot(filtertime,Kres,'LineWidth',2)\nset(gca,'box','on','LineWidth',2,'FontSize',font_size)\nxlabel('Lag (s)','FontSize',20)\nylabel('Filter Amplitude','FontSize',font_size)\ntitle('Filter: PID > residuals','FontSize',20)\n\n%%\n% and use this filter to predict the residuals from the stimulus. \nresp = filter(Kres,1,PID-mean(PID)) + mean2(res);\nfigure('outerposition',[10 10 1000 600],'PaperUnits','points','PaperSize',[1000 600]); hold on\nplot(time,res,'k','LineWidth',2)\nplot(time,resp,'b','LineWidth',2)\nset(gca,'XLim',[mean(time)-1 mean(time)+2],'box','on','LineWidth',2,'FontSize',18)\nxlabel('Time','FontSize',20)\nylabel('Residuals','FontSize',font_size)\nlegend Residuals 'Predicted Residuals'\n\n%%\n% Does adding this back to the prediction improve the prediction? The following plot shows the data (black), the linear prediction (red), and the linear prediction corrected by the prediciton of the residual (green).\nfpr = fp + resp;\nfigure('outerposition',[10 10 1000 600],'PaperUnits','points','PaperSize',[1000 600]); hold on\nplot(time,f,'k','LineWidth',2)\nplot(time,fp,'r','LineWidth',2)\nplot(time,fpr,'g','LineWidth',2)\nset(gca,'XLim',[mean(time)-1 mean(time)+2],'box','on','LineWidth',2,'FontSize',18)\nxlabel('Time','FontSize',20)\nylabel('Residuals','FontSize',font_size)\nlegend Data 'Linear Prediction' 'Residual Corrected'\n\n%%\n% The r-square of the corrected prediction is\ndisp(rsquare(f(filter_length+2:end),fpr(filter_length+2:end)))\n\n%% \n% and the r-square of the simple linear prediction is\ndisp(rsquare(f(filter_length+2:end),fp(filter_length+2:end)))\n\n%%\n% How does this make any sense? If this is true, then simply adding the filters together will yield a better filter, which we should have computed in the very beginning. The filter, the second filter computed from residuals, and their sum is shown in the panel on the left. On the right is a filter with lower regularisation. \n\nfigure('outerposition',[0 0 800 350],'PaperUnits','points','PaperSize',[800 350]); hold on\nsubplot(1,2,1), hold on\nplot(filtertime,K,'k','LineWidth',2)\nplot(filtertime,Kres,'r','LineWidth',2)\nplot(filtertime,Kres+K,'g','LineWidth',2)\nlegend Filter ResidualFilter Sum\nset(gca,'FontSize',font_size,'LineWidth',2,'box','on')\nylabel('Filter Amplitude (Hz)','FontSize',font_size)\n\nK_lowreg = FitFilter2Data(PID,f,'reg=1e-1;');\nsubplot(1,2,2), hold on\nplot(filtertime,K_lowreg,'k','LineWidth',2)\ntitle('Filter with low regularisation','FontSize',font_size)\nset(gca,'FontSize',font_size,'LineWidth',2,'box','on')\nxlabel('Time (s)','FontSize',font_size)\n\n%%\n% So what we are doing is simply undoing the work we did in regularising the filter. \n\n%% Analysis of Gain: Instantaneous Gain and Fitted Gain\n% There is a mismatch between the linear prediction and the actual firing rate. Moreover, the instantaneous gain seems to be modulated by something that depends on the past history of the stimulus (see analysis in the previous section). We also know that we cannot predict with a simple linear filter any linear errors that the filter makes. However, there is the possibility of fitting a linear filter to the gain, which is a non-linear function of the filter output. But how do we compute this gain? Here, in the figure below, the instantaneous gain, i.e., the ratio of the actual firing rate to the predicted firing rate, is plotted along with the stimulus. \n\ng = f./fp;\nfigure('outerposition',[0 0 800 350],'PaperUnits','points','PaperSize',[800 350]); hold on\nsubplot(2,1,1), hold on\nplot(time,g,'k','LineWidth',2)\nset(gca,'XLim',[mean(time)-2 mean(time)+2],'FontSize',font_size,'LineWidth',2,'box','on','YLim',[0 2])\nylabel('Gain','FontSize',font_size)\nsubplot(2,1,2), hold on\nplot(time,PID,'k','LineWidth',2)\nylabel('PID','FontSize',font_size)\nset(gca,'XLim',[mean(time)-1 mean(time)+2],'FontSize',font_size,'LineWidth',2,'box','on')\nxlabel('Time (s)','FontSize',font_size)\n\n%%\n% We can also calculate the moving gain by fitting lines to the data and the prediction collected in bins of size _w_. The following plots show the gain computed in this way for a few different _w_. We want to do this because the raw instantaneous gain is very noisy, and predicting it from PID is hard. \n\n% WARNING. THIS CODE IS SUPER SLOW. FITTING THOUSANDS OF LINES. \n% we're going to cheat and pre-load data\nws = [5 10 30 100];\nif ~(exist('gain') == 1)\n	% gain = f./fp;\n	% gain = repmat(gain,1,length(ws)+1);\n	% for i = 1:length(ws)\n	% 	disp(i)\n	% 	starthere = filter_length+2+ws(i);\n	% 	for j = starthere:1:length(f)\n	% 		j\n	% 		fitmetrics = fit(fp(thesepoints),f(thesepoints),'Poly1');\n	% 		gain(j,i+1) = fitmetrics.p1;\n	% 	end\n	% end\n	load('gain.mat')\nend\n\nws = [1 ws];\nfigure('outerposition',[10 10 1000 600],'PaperUnits','points','PaperSize',[1000 600]); hold all\nlegendtext = {};\nfor i = 1:size(gain,2)\n	plot(time,gain(:,i))\n	legendtext{i} = strcat('Window size:',mat2str(ws(i)*3),'ms');\nend\nset(gca,'XLim',[mean(time)-2 mean(time)+2],'LineWidth',2,'box','on','FontSize',font_size)\nlegend(legendtext)\nxlabel('Time (s)','FontSize',font_size)\nylabel('Gain (f/fp)','FontSize',font_size)\n\n%%\n% Of these different gain vectors, which fixes the prediction the best? The following plot shows the r-square values of corrected linear prediction, corrected by the gain computed in different ways (lines fit to windows of different lengths). On the y-axis is the r-square, and the x-axis is the window over which the lines are fit.  The first point has a r-square of 1, indicating a perfect fit (this is by definition, since the first point is the instantaneous gain). Note that none of the other points exceed the line, which indicates the r-square of the simple linear prediction. \nfpg = f;\nfpg = repmat(fpg,1,length(ws));\nfor i = 1:length(ws)\n	fpg(:,i) = fp.*gain(:,i);\nend\n\nrvalues = NaN(1,length(ws));\nfor i = 1:length(ws)\n	rvalues(i) = rsquare(f(filter_length+2:end),fpg(filter_length+2:end,i));\nend\n\nfigure('outerposition',[10 10 400 400],'PaperUnits','points','PaperSize',[1000 400]); hold on\nplot(ws*3,rvalues,'.','MarkerSize',marker_size2)\nxlabel('Window over which slope is fitted (ms)','FontSize',font_size)\nylabel('r-square of corrected fit','FontSize',font_size)\nline([1 max(ws)*3],[rsquare(f(filter_length+2:end),fp(filter_length+2:end)) rsquare(f(filter_length+2:end),fp(filter_length+2:end))],'LineWidth',2)\nset(gca,'LineWidth',2,'FontSize',font_size)\n\n%%\n% We conclude that this method of finding the gain is not helpful in improving the prediction. \n\n%% Analysis of Gain: Smoothed gain. \n% Instead of calculating the instantaneous point-by-point gain, we can also smooth the instantaneous gain over some small window size _w_. The following plot shows the effect of smoothing for a few window sizes _w_. \ngain2 = f./fp;\nws = [1 5 10 25 50 100];\ngain2 = repmat(gain2,1,length(ws));\nfor i = 1:length(ws)\n	gain2(:,i)=smooth(gain2(:,i),ws(i));	\nend\n\nfigure('outerposition',[10 10 1000 600],'PaperUnits','points','PaperSize',[1000 600]); hold all\nlegendtext = {};\nfor i = 1:size(gain2,2)\n	plot(time,gain2(:,i),'LineWidth',2)\n	legendtext{i} = strcat('Window size:',mat2str(ws(i)*3),'ms');\nend\nset(gca,'XLim',[mean(time)-2 mean(time)+2],'LineWidth',2,'box','on','FontSize',font_size)\nlegend(legendtext)\nxlabel('Time (s)','FontSize',font_size)\nylabel('Gain (f/fp)','FontSize',font_size)\n\n%%\n% How does smoothing the gain affect our ability to correct the linear prediction? The following plot shows how the r-square of the corrected linear prediction varies with smoothing the gain. Also shown is the line which indicates the linear prediction of the uncorrected simple linear prediction. \n\nfpg = f;\nfpg = repmat(fpg,1,length(ws));\nfor i = 1:length(ws)\n	fpg(:,i) = fp.*gain2(:,i);\nend\n\nrvalues = NaN(1,length(ws));\nfor i = 1:length(ws)\n	rvalues(i) = rsquare(f(filter_length+2:end),fpg(filter_length+2:end,i));\nend\n\nfigure('outerposition',[10 10 400 400],'PaperUnits','points','PaperSize',[1000 400]); hold on\nplot(ws*3,rvalues,'.','MarkerSize',marker_size2)\nxlabel('Smoothing window (ms)','FontSize',font_size)\nylabel('r-square of corrected fit','FontSize',font_size)\nline([1 max(ws)*3],[rsquare(f(filter_length+2:end),fp(filter_length+2:end)) rsquare(f(filter_length+2:end),fp(filter_length+2:end))],'LineWidth',2)\nset(gca,'LineWidth',2,'FontSize',font_size)\n\n%%\n% From this analysis of the gain, it is clear that if we do want to improve the linear prediction, the best way to do it (apart from the instantaneous gain, which would lead to a perfect prediction), is smoothing the gain in some way. In the next section, we will try to estimate the smoothed gain.\n\n%% Gain Analysis - Estimating the gain \n% In the above analysis, we have considered how a boxcar average over the stimulus immediately preceding the current time affects gain. Now, we want to find some optimal way of averaging the past stimulus history to predict the instantaneous gain: by doing so, we can then predict gain, and thus get a better predictor of the actual firing rate.\n\n%%\n% In effect, we can calculate a new filter, $K_g$ such that \n% \n% $$ K_g=\\hat{C}\\setminus(s'*g) $$\n%\n% where _g_ is the smoothed gain and _s_ is the stimulus. \n\n%%\n% For with various smoothing of the instantaneous gain, we find the best filter for each and plot it below:\n\nif ~(exist('Kg_smooth') == 1)\n	Kg_smooth = zeros(filter_length+1,size(gain2,2));\n	for i = 1:size(gain2,2)\n		Kg_smooth(:,i) = FindBestFilter(PID(filter_length+2:end),gain2(filter_length+2:end,i),filter_length);\n	end\n\nend\n\n\nfigure('outerposition',[10 10 600 600],'PaperUnits','points','PaperSize',[1000 600]); hold on\nplot(filtertime,Kg_smooth,'LineWidth',2)\nxlabel('Filter Lag','FontSize',font_size)\nylabel('Filter Amplitude','FontSize',font_size)\nset(gca,'LineWidth',2,'FontSize',font_size,'box','on')\nlegend(legendtext)\n\n%%\n% How well can we predict the smoothed gain vectors using these filters and the stimulus? The following plot shows the r-square between prediction of the smoothed gain and the smoothed gain for various smoothing windows. \n\ngain2p = gain2;\nfor i = 1:length(ws)\n	gain2p(:,i) = filter(Kg_smooth(:,i),1,PID-mean(PID)) + mean2(gain2(filter_length+2:end,i));\nend\n\nrvalues = NaN(1,length(ws));\nfor i = 1:length(ws)\n	rvalues(i) = rsquare(gain2p(filter_length+2:end,i),gain2(filter_length+2:end,i));\nend\n\nfigure('outerposition',[10 10 400 400],'PaperUnits','points','PaperSize',[1000 400]); hold on\nplot(ws*3,rvalues,'.','MarkerSize',marker_size2)\nxlabel('Smoothing window (ms)','FontSize',font_size)\nylabel('r-square','FontSize',font_size)\nset(gca,'LineWidth',2,'FontSize',font_size)\n\n%%\n% Well, that sucks. Maybe even this horrible estimation of the gain can improve the linear prediction of the firing rate in some way? Here, I plot the r-square of the gain-corrected linear prediction (corrected by the prediction of the gain), as a function of gain smoothing (in blue). Also plotted is the r-square of the gain-corrected linear prediction, corrected now with actual gain (in black).\n\n\nfpg = f;\nfpg = repmat(fpg,1,length(ws));\nfor i = 1:length(ws)\n	fpg(:,i) = fp.*gain2(:,i);\nend\n\nrvalues = NaN(1,length(ws));\nfor i = 1:length(ws)\n	rvalues(i) = rsquare(f(filter_length+2:end),fpg(filter_length+2:end,i));\nend\n\n\nfpg = f;\nfpg = repmat(fpg,1,length(ws));\nfor i = 1:length(ws)\n	fpg(:,i) = fp.*gain2p(:,i);\nend\n\nrvalues2 = NaN(1,length(ws));\nfor i = 1:length(ws)\n	rvalues2(i) = rsquare(f(filter_length+2:end),fpg(filter_length+2:end,i));\nend\n\n\nfigure('outerposition',[10 10 400 400],'PaperUnits','points','PaperSize',[1000 400]); hold on\nplot(ws*3,rvalues,'b.','MarkerSize',marker_size2), hold on\nplot(ws*3,rvalues2,'k.','MarkerSize',marker_size2)\nxlabel('Smoothing window (ms)','FontSize',font_size)\nylabel('r-square of corrected fit','FontSize',font_size)\nline([1 max(ws)*3],[rsquare(f(filter_length+2:end),fp(filter_length+2:end)) rsquare(f(filter_length+2:end),fp(filter_length+2:end))],'LineWidth',2)\nset(gca,'LineWidth',2,'FontSize',font_size)\n\n\n\n%% Next Steps\n% \n% # Calculate filters for high and low stimulus zones. \n% # Calculate filters after using elastic net regularisation. \n% # Check if someone has looked at Weber's law in olfaction/ORNs\n% # shuffle data to check validity?\n% # fit Dynamical Adaptation model to data?\n\n%% Docs\n% This document was generated by MATLAB's publish function. All files needed to generate this document are on a git repository on https://bitbucket.org/srinivasgs/da\n\n% close all to remove all extraneous figures, since we are publishing to a document anyway\nclose all",
			"file": "Analysis_January.m",
			"file_size": 27381,
			"file_write_time": 1390833854000000,
			"settings":
			{
				"buffer_size": 27354,
				"line_ending": "Unix",
				"name": "%% Dynamical Adaptation in ORNs"
			}
		},
		{
			"file": "FindBestFilter.m",
			"settings":
			{
				"buffer_size": 4095,
				"line_ending": "Unix",
				"name": "function [K Kdamon] = FindBestFilter(PID,f,filter_"
			}
		},
		{
			"file": "FitFilter2Data.m",
			"settings":
			{
				"buffer_size": 2822,
				"line_ending": "Unix"
			}
		},
		{
			"file": "FilterEstimation.m",
			"settings":
			{
				"buffer_size": 10966,
				"line_ending": "Unix",
				"name": "%% Filter Estimation"
			}
		},
		{
			"file": "PlotFilterDiagnostics2.m",
			"settings":
			{
				"buffer_size": 2331,
				"line_ending": "Unix"
			}
		},
		{
			"file": "Analysis_January_unused.m",
			"settings":
			{
				"buffer_size": 7669,
				"line_ending": "Unix"
			}
		}
	],
	"build_system": "",
	"command_palette":
	{
		"height": 287.0,
		"selected_items":
		[
			[
				"Package Control: ",
				"Package Control: List Packages"
			],
			[
				"disab",
				"Package Control: Disable Package"
			],
			[
				"disable",
				"Package Control: Disable Package"
			],
			[
				"packa",
				"Package Control: Disable Package"
			],
			[
				"install",
				"Package Control: Install Package"
			],
			[
				"save",
				"File: Save All"
			],
			[
				"newfile",
				"File: New View into File"
			],
			[
				"sidebar",
				"View: Toggle Side Bar"
			],
			[
				"syntax js",
				"Set Syntax: JavaScript"
			],
			[
				"syntax matlb",
				"Set Syntax: MATLAB"
			],
			[
				"Package Control: Install",
				"Package Control: Install Package"
			],
			[
				"disp",
				"Snippet: disp"
			],
			[
				"error",
				"Snippet: error"
			],
			[
				"Snippet: error",
				"Snippet: error"
			]
		],
		"width": 449.0
	},
	"console":
	{
		"height": 125.0
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"file_history":
	[
		"/Users/sigbhu/Dropbox/code/core/multiplot.m",
		"/Users/sigbhu/Dropbox/code/core/std2.m",
		"/Users/sigbhu/Dropbox/code/core/mean2.m",
		"/Users/sigbhu/Dropbox/code/DA/html/FilterEstimation.synctex.gz",
		"/Users/sigbhu/Dropbox/code/DA/PlotFilterDiagnostics.m",
		"/Users/sigbhu/Dropbox/code/DA/larsen.m",
		"/Users/sigbhu/Dropbox/code/DA/elasticnet.m",
		"/Users/sigbhu/Dropbox/code/DA/build_LNmodel_reg.m",
		"/Users/sigbhu/Dropbox/code/DA/build_LNmodel_optreg.m",
		"/Users/sigbhu/Dropbox/code/DA/Back_out_1dfilter_new.m",
		"/Users/sigbhu/Dropbox/code/DA/Analysis_January_unused.m",
		"/Volumes/emonetlab/home/PAST/carlotta_martelli/laptop_backup/Documents/MATLAB/my_MATLAB/spasm/elasticnet.m",
		"/Users/sigbhu/Dropbox/code/DA/SlopeProblem.m",
		"/Users/sigbhu/Dropbox/code/DA/srinivas_latex.xsl",
		"/Users/sigbhu/Dropbox/code/DA/AnalyseLinearPrediction.m",
		"/Library/WebServer/Documents/wiki/LocalSettings.php",
		"/WebServer/Documents/wiki/LocalSettings.php",
		"/Users/sigbhu/file",
		"/Users/sigbhu/Dropbox/code/DA/srinivas.xsl",
		"/Users/sigbhu/Dropbox/code/DA/analysis_old_data.m",
		"/Users/sigbhu/Library/Application Support/Sublime Text 2/Packages/User/Preferences.sublime-settings",
		"/Users/sigbhu/Dropbox/code/DA/temp.m",
		"/Users/sigbhu/Dropbox/code/DA/2012_05_23_analysis_old_data.m",
		"/Users/sigbhu/Dropbox/code/DA/FitFilter2Data.m",
		"/Users/sigbhu/Dropbox/code/DA/publish2.m",
		"/Users/sigbhu/Dropbox/code/DA/AnalyseAllData.m",
		"/Users/sigbhu/Dropbox/code/DA/test.m",
		"/Users/sigbhu/Dropbox/code/DA/build_LNmodel_allvalues.m",
		"/Users/sigbhu/Dropbox/code/DA/PrepData2.m",
		"/Users/sigbhu/Dropbox/code/DA/PrepData.m",
		"/Users/sigbhu/Dropbox/code/DA/bin_traces.m",
		"/Users/sigbhu/Dropbox/code/DA/DA_integrate.m",
		"/Users/sigbhu/Dropbox/code/DA/File_S1.m",
		"/Users/sigbhu/Dropbox/code/DA/errorbar_cazzo.m",
		"/Users/sigbhu/Dropbox/code/DA/DA_integrate_euler.m",
		"/Users/sigbhu/Dropbox/code/DA/DA_cost_function.m",
		"/Users/sigbhu/Dropbox/code/DA/DA_integrate_tubro.m",
		"/Users/sigbhu/Dropbox/code/DA/DA_cost_function_dummy.m",
		"/Users/sigbhu/Dropbox/code/DA/File_S2.m",
		"/Users/sigbhu/Dropbox/code/code.todo",
		"/Users/sigbhu/Dropbox/code/tracking/Track2.m",
		"/Users/sigbhu/Dropbox/code/bash/wfmount.sh",
		"/Users/sigbhu/Dropbox/code/bash/.newton",
		"/.newton",
		"/RSSBlackList.txt",
		"/Users/sigbhu/Dropbox/code/b/FileName2GenoDate.m",
		"/Users/sigbhu/Dropbox/code/b/TFAViewer2.m",
		"/Users/sigbhu/Dropbox/code/b/PlotTFAResponses3.m",
		"/Users/sigbhu/Dropbox/code/core/TrialPlot.m",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonet.biology.yale.edu/pages/people.html",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonet.biology.yale.edu/nfsim/download/index.php",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonet.biology.yale.edu/nfsim/download/processRegistration.php",
		"/Users/sigbhu/.ssh/known_hosts",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonet.biology.yale.edu/pages/publications.html",
		"/Users/sigbhu/Dropbox/code/zoidberg/make_fig_15_metrics.m",
		"/Users/sigbhu/Dropbox/code/b/PlotTFAResponses2.m",
		"/Users/sigbhu/Dropbox/code/b/PlotTrialVariability.m",
		"/Users/sigbhu/Dropbox/code/b/AnalyseAirspeedsMultiPuffs.m",
		"/Users/sigbhu/Dropbox/code/b/PlotDoseResponses.m",
		"/Users/sigbhu/Dropbox/code/b/PlotTFATurns.m",
		"/Users/sigbhu/Dropbox/code/b/PlotTFAPIDAirspeeds.m",
		"/Users/sigbhu/Dropbox/code/b/Convert2v2.m",
		"/Users/sigbhu/Dropbox/code/b/PlotPIDResponse.m",
		"/Users/sigbhu/Dropbox/code/core/FrameGrabM/FrameGrabM_0_8/Readme.txt",
		"/Users/sigbhu/Dropbox/code/b/AnalysePIDMultiPuffs3.m",
		"/Users/sigbhu/Dropbox/code/core/oval.m",
		"/Users/sigbhu/Dropbox/code/b/AnalysePIDMultiPuffs.m",
		"/Users/sigbhu/Dropbox/code/b/AnalysePIDMultiPuffs2.m",
		"/Users/sigbhu/Library/Application Support/Sublime Text 2/Packages/Default/Preferences.sublime-settings",
		"/Users/sigbhu/Dropbox/code/b/AnalyseTrialTrends.m",
		"/Users/sigbhu/Library/Application Support/Sublime Text 2/Packages/User/Snippets/matlab_snippets/plot(ts,linespec).sublime-snippet",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonet.biology.yale.edu/index.html",
		"/Users/sigbhu/Library/Application Support/Sublime Text 2/Packages/Default/Default (OSX).sublime-keymap",
		"/Users/sigbhu/Library/Application Support/Sublime Text 2/Packages/User/Matlab.sublime-settings",
		"/Users/sigbhu/Downloads/soda-theme-master/Soda Dark.sublime-theme",
		"/Users/sigbhu/Library/Application Support/Sublime Text 2/Packages/User/JSON.sublime-settings",
		"/Users/sigbhu/Dropbox/code/b/PlotTFAResponses.m",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonet.biology.yale.edu/pages/resources.html",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/biology.yale.edu/index.html",
		"/Users/sigbhu/.ssh/id_rsa.pub",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/85b5b59a-4356-47dc-8aa5-5b910dd73d40/seldon/2/index.html",
		"/web/seldon/3/index.html",
		"/web/seldon/3/css/base.css",
		"/Users/sigbhu/Desktop/Untitled.html",
		"/Users/sigbhu/Desktop/Untitled.webarchive",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/85b5b59a-4356-47dc-8aa5-5b910dd73d40/index.html",
		"/web/seldon/1/index.html",
		"/web/seldon/1/css/skeleton.css",
		"/web/seldon/1/css/layout.css",
		"/web/seldon/1/css/docs.css",
		"/web/seldon/1/css/base.css",
		"/web/seldon/2/index.html",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/85b5b59a-4356-47dc-8aa5-5b910dd73d40/seldon/1/index.html",
		"/web/seldon/index.html",
		"/web/seldon/2/css/base.css",
		"/Users/sigbhu/Desktop/My Notes/1: Introduction.html",
		"/Users/sigbhu/Dropbox/lobster_draft/data/STGDataExplorer.m",
		"/Users/sigbhu/Dropbox/code/orn-analysis/spikesort_7_19_a.m",
		"/Users/sigbhu/Dropbox/code/zoidberg/STG.m",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonet.biology.yale.edu/nfsim/pages/feedback.php",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonet.biology.yale.edu/nfsim/index.html",
		"/labweb/pages/people.html",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonet.biology.yale.edu/pages/contact.html",
		"/private/etc/hosts",
		"/Users/sigbhu/Desktop/feedback.php",
		"/Users/sigbhu/Desktop/processRegistration.php",
		"/Users/sigbhu/Desktop/index.php",
		"/Users/sigbhu/Desktop/index.html",
		"/labweb/pages/contact.html",
		"/Users/sigbhu/Desktop/Daring Fireball: Email.html",
		"/Users/sigbhu/Dropbox/lobster_draft/data/ZoidbergExplorer.m",
		"/Users/sigbhu/Dropbox/code/zoidberg/RecomputePyloricityCodes.m",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/85b5b59a-4356-47dc-8aa5-5b910dd73d40/essays/books/index.html",
		"/Users/sigbhu/Desktop/My Notes/5: Brace for the coming Food Riots.html",
		"/web/seldon/books/index.html",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/98bf81be-fb5d-403c-ae0a-9b72c407caf0/emonetnew.biology.yale.edu/nfsim/index.html",
		"/labweb/pages/software.html",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/85b5b59a-4356-47dc-8aa5-5b910dd73d40/b/css.css",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/85b5b59a-4356-47dc-8aa5-5b910dd73d40/articles/children-of-men/index.html",
		"/private/var/folders/gq/0hzwy57n79d1813pnfy51mmr0000gn/T/85b5b59a-4356-47dc-8aa5-5b910dd73d40/articles/books/index.html",
		"/web/articles/children-of-men/css/base.css",
		"/web/articles/children-of-men/index.html",
		"/web/articles/books/index.html",
		"/web/articles/books/css/base.css",
		"/web/articles/books/css/skeleton.css",
		"/web/articles/books/css/docs.css",
		"/web/articles/books/css/layout.css",
		"/labweb/pages/publications.html"
	],
	"find":
	{
		"height": 35.0
	},
	"find_in_files":
	{
		"height": 0.0,
		"where_history":
		[
			"AnalyseLinearPrediction.m,/Users/sigbhu/Dropbox/code/DA",
			"AnalyseLinearPrediction.m",
			"FitFilter2Data.m",
			"FitFitler2Data.m"
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"gain",
			"r-s",
			"r-square",
			"fit",
			"plot(time,",
			"S is the",
			"diagnostics.C.",
			"FindBest",
			"marker_size",
			"PLotFil",
			"fall",
			"Slope of fp/f",
			"= fit",
			"[fall",
			"gain",
			"diagnostics_gain",
			"diagnostics_fake",
			"FindBestFil",
			"FitFilter2Data",
			"search algo",
			"gain = ",
			"gain",
			"return",
			"fp",
			"FindBestFilter",
			"fit",
			"filter_length+1",
			"STA",
			"title",
			"STA",
			"filter(Kdamon",
			"fpd =",
			"fp=",
			"Kdamon",
			"[350 350]",
			"[0 0 500 500]",
			"[500 500]",
			"'outerposition',[700 700]",
			"'outerposition',[1000 700]",
			"figure, hold on",
			"latex",
			"ylabel",
			"disp",
			"gain",
			"filter",
			"k",
			"MakerFaceColor",
			"MarkerSize",
			"fit",
			"fir",
			"thisfp",
			"hl",
			"history_lengths",
			"memory",
			"f",
			"a",
			"lambda_i",
			"fitfun",
			"figon",
			"stim",
			"memory",
			"a_notnormalised",
			"D",
			"v",
			"fp1",
			"fitfun",
			"D_final",
			"hist",
			"past_window",
			"marker_size",
			"scatter",
			"15",
			"fsd",
			"reg_vec",
			"response",
			"f",
			"files",
			"33",
			"35",
			"time",
			"collision",
			"stats",
			"nfig",
			"figure",
			"Turns",
			"Thrust",
			"Thrusts",
			"allfiles",
			"sem",
			"line",
			"equalise",
			"figure",
			"thesetrials",
			"thesetrials =",
			"thesetrials",
			"TrialPlot",
			"plottrials",
			"plotthis",
			"plot",
			"/dt",
			"3",
			"title",
			"odour",
			"FileName",
			"title",
			"FileName2",
			"plot(",
			"sublime",
			"plot",
			"TrialPlot",
			"gca",
			"a",
			"a(3)",
			"TrialPlot",
			"subplot",
			"mx",
			"dt",
			"title",
			"wbfylim",
			"thrustylim",
			"wbfylim",
			"TrialPlot",
			"Trial",
			"fly",
			"fit",
			"Airspeed",
			"Maximum",
			"Airspeed"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": false,
		"replace_history":
		[
			"diagnostics.",
			"Gain",
			"diagnostics_fake",
			"diagnostics_gain",
			"filter_length+2",
			"[800 350]",
			"[0 0 350 350]",
			"[350 350]",
			"'outerposition',[10 10 1000 700]",
			"fp",
			"filter_length",
			"response",
			"thisfp",
			"history_lengths",
			"marker_size",
			"rs",
			"reg",
			"f",
			"response",
			"31",
			"33",
			"t",
			"PID",
			"",
			"s2",
			"s3",
			"PY",
			"LP",
			"AB"
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "Analysis_January.m",
					"settings":
					{
						"buffer_size": 27354,
						"regions":
						{
						},
						"selection":
						[
							[
								19379,
								19379
							]
						],
						"settings":
						{
							"auto_name": "%% Dynamical Adaptation in ORNs",
							"syntax": "Packages/Matlab/Matlab.tmLanguage",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 7984.0,
						"zoom_level": 1.0
					},
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "FindBestFilter.m",
					"settings":
					{
						"buffer_size": 4095,
						"regions":
						{
						},
						"selection":
						[
							[
								2083,
								2085
							]
						],
						"settings":
						{
							"auto_name": "function [K Kdamon] = FindBestFilter(PID,f,filter_",
							"syntax": "Packages/Matlab/Matlab.tmLanguage",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "FitFilter2Data.m",
					"settings":
					{
						"buffer_size": 2822,
						"regions":
						{
						},
						"selection":
						[
							[
								2332,
								2332
							]
						],
						"settings":
						{
							"syntax": "Packages/Matlab/Matlab.tmLanguage",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 1008.0,
						"zoom_level": 1.0
					},
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "FilterEstimation.m",
					"settings":
					{
						"buffer_size": 10966,
						"regions":
						{
						},
						"selection":
						[
							[
								2886,
								2889
							]
						],
						"settings":
						{
							"auto_name": "%% Filter Estimation",
							"syntax": "Packages/Matlab/Matlab.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 1031.0,
						"zoom_level": 1.0
					},
					"type": "text"
				},
				{
					"buffer": 4,
					"file": "PlotFilterDiagnostics2.m",
					"settings":
					{
						"buffer_size": 2331,
						"regions":
						{
						},
						"selection":
						[
							[
								96,
								14
							]
						],
						"settings":
						{
							"syntax": "Packages/Matlab/Matlab.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"type": "text"
				},
				{
					"buffer": 5,
					"file": "Analysis_January_unused.m",
					"settings":
					{
						"buffer_size": 7669,
						"regions":
						{
						},
						"selection":
						[
							[
								7668,
								7668
							]
						],
						"settings":
						{
							"syntax": "Packages/Matlab/Matlab.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 2403.0,
						"zoom_level": 1.0
					},
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 36.0
	},
	"input":
	{
		"height": 0.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"replace":
	{
		"height": 64.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"selected_items":
		[
			[
				"mult",
				"/Users/sigbhu/Dropbox/code/core/multiplot.m"
			],
			[
				"build_lnmodel_optreg",
				"build_LNmodel_optreg.m"
			],
			[
				"pre",
				"PrepData2.m"
			],
			[
				"prep",
				"PrepData2.m"
			],
			[
				"all",
				"build_LNmodel_allvalues.m"
			],
			[
				"build_lnmodel_reg",
				"build_LNmodel_reg.m"
			],
			[
				"build_lnmodel_allvalues",
				"build_LNmodel_allvalues.m"
			],
			[
				"bin",
				"bin_traces.m"
			],
			[
				"",
				"DA_integrate_tubro.m"
			],
			[
				"trial",
				"core/TrialPlot.m"
			],
			[
				"filenam",
				"b/FileName2GenoDate.m"
			],
			[
				"plot",
				"b/PlotTFAResponses2.m"
			],
			[
				"plottfa",
				"b/PlotTFAResponses2.m"
			],
			[
				"conver",
				"b/Convert2v2.m"
			],
			[
				"pid",
				"b/PlotTFAPIDAirspeeds.m"
			],
			[
				"tria",
				"core/TrialPlot.m"
			],
			[
				"tuns",
				"b/PlotTFATurns.m"
			],
			[
				"plotdose",
				"b/PlotDoseResponses.m"
			],
			[
				"file",
				"b/FileName2GenoDate.m"
			],
			[
				"oval",
				"core/oval.m"
			],
			[
				"anlysepi",
				"b/AnalysePIDMultiPuffs.m"
			],
			[
				"analysepid",
				"b/AnalysePIDMultiPuffs3.m"
			],
			[
				"analyseair",
				"b/AnalyseAirspeedsMultiPuffs.m"
			],
			[
				"plotres2",
				"b/PlotTFAResponses2.m"
			],
			[
				"plottr",
				"PlotTrialVariability.m"
			],
			[
				"plotdos",
				"PlotDoseResponses.m"
			],
			[
				"tfa",
				"TFAViewer2.m"
			],
			[
				"plottf",
				"PlotTFAResponses2.m"
			],
			[
				"plottri",
				"PlotTrialVariability.m"
			],
			[
				"error",
				"/Users/sigbhu/Dropbox/code/b/PlotDoseResponses.m"
			]
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 0.0,
		"selected_items":
		[
		],
		"width": 0.0
	},
	"show_minimap": true,
	"show_open_files": false,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 215.0,
	"status_bar_visible": true
}
