

pHeader;

%% Reverse Filter analysis
% In this document, I assume NL-type models underlie data that we have, and attempt to a) recover this input nonlinearity non-parametrically and b) check if this input nonlinearity changes with stimulus condition or time. The way I do this is to first extract a filter from the response to the stimulus (a-causally), and then to plot the stimulus vs. projected response. 

%% Validation with synthetic data: naturalistic stimuli
% First, I validate this analysis method using synthetic data from a DA model. In the following figure, I use three different DA models run on the sparse naturalistic stimulus in Fig 2 of the paper:

%%
% 
% # A DA model fit to the naturalistic stimulus data (first row) 
% # The same DA model, but with gain control turned off (by setting B := 0) (second row)
% # The same model as in the first row, but forcing the $K_z$ and $K_y$ filters to be the same (third row). This effective transforms the DA model into a LN model. 

%%
% In each row, the first column shows the parameters (filters) of the DA model I used to generate the synthetic data. The second column shows the reconstructed filters (from the response to the stimulus). Note that in all cases, most of the filter is a-causal (negative time is in the future). In the third column, I'm plotting the convolution of the filter with the response generated by the DA model vs. the stimulus. This is the reconstructed input nonlinearity. I'm colouring the points by the mean stimulus in the preceding 300ms (log-weighted). In (c), estimated stimulus correlates poorly with the stimulus. Is this because of the fast gain control or is it because of the inherent nonlinearity involved in the DA model? Let's see: In (f), where there is no gain control (by construction), the estimated stimulus correlates well with the stimulus. However, in (i), where there is also no gain control, but where I am fitting a NL model to LN model responses, we see apparent movement of the input nonlinearity. 

%%
% (c) looks very similar to (i). I can't tell these two apart. So it's hard to distinguish "true gain control" from a LN model using this approach. (What is not shown is that it is also hard to distinguish true gain control from a NL model by fitting models to the data). 


% get the first nat. stim
load(getPath(dataManager,'5c7dacc5b42ff0eebb980d80fec120c3'),'data','spikes')
PID = data(2).PID;
fA = spiketimes2f(spikes(2).A,1e-4*(1:length(PID)));
fA = mean(fA,2);
PID = PID(:,1:10:end)';
PID = PID - min(min(PID(1:5e3,:)));
S = mean(PID,2);
time = 1e-3*(1:length(S));

% fit a DA model to this
clear p
p.   s0 = 0;
p.  n_z = 2;
p.tau_z = 147.3750;
p.  n_y = 2;
p.tau_y = 27.2500;
p.    C = 0.5000;
p.    A = 170.4375;
p.    B = 2.7656;

[R0,~,~,Ky,Kz] = DAModelv2(S,p);

% now generate another set of responses with the dynamical adaptation turned off
p.B = 0;
R1 = DAModelv2(S,p);

% and another one which is effectively a LN model
p.B = 2.7656;
p.C = 1;
[R2,~,~,~,Kz_2] = DAModelv2(S,p);

% treat t the stimulus and the response as each other, and flip time
K0 = fitFilter2Data(R0,S,'reg',1,'filter_length',1e3,'offset',600);
filtertime = 1e-3*(1:length(K0)) - .6;
S0 = convolve(time,R0,K0,filtertime)/max(R0);

K1 = fitFilter2Data(R1,S,'reg',1,'filter_length',1e3,'offset',600);
S1 = convolve(time,R1,K1,filtertime)/max(R1);

K2 = fitFilter2Data(R2,S,'reg',1,'filter_length',1e3,'offset',600);
S2 = convolve(time,R2,K2,filtertime)/max(R2);

history_length = 300;

figure('outerposition',[0 0 910 902],'PaperUnits','points','PaperSize',[910 902]); hold on
subplot(3,3,1); hold on
plot(Ky*1e3)
plot(Kz*1e3)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

subplot(3,3,2); hold on
plot(filtertime,K0,'k')
xlabel('Lag (s)')
ylabel('Filter amplitude (a.u.)')
title('Reconstructed filters (R \rightarrow S)')
set(gca,'XLim',[-.6 .2])

subplot(3,3,3); hold on
shat = computeSmoothedStimulus(S,history_length);
shat = shat-min(shat);
shat = log(1+shat);
shat = shat/max(shat);
shat = 1 + ceil(shat*99);
shat(isnan(shat)) = 1;
cc = parula(100);
c = cc(shat,:);
scatter(S,S0,20,c,'filled')
set(gca,'XScale','log')
legend(['r^2 = ' oval(rsquare(S,S0))],'Location','northwest')
set(gca,'XTick',[1e-2 1e-1 1 10],'XLim',[1e-3 10])
xlabel('Stimulus (V)')
ylabel('K \otimes R (norm)')
title('"True gain control"')

subplot(3,3,4); hold on
plot(Ky*1e3)
plot(Kz*0)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

subplot(3,3,5); hold on
plot(filtertime,K1,'k')
xlabel('Lag (s)')
ylabel('Filter amplitude (a.u.)')
title('Reconstructed filters (R \rightarrow S)')
set(gca,'XLim',[-.6 .2])

subplot(3,3,6); hold on
scatter(S,S1,20,c,'filled')
set(gca,'XScale','log')
legend(['r^2 = ' oval(rsquare(S,S1))],'Location','northwest')
set(gca,'XTick',[1e-2 1e-1 1 10],'XLim',[1e-3 10])
xlabel('Stimulus (V)')
ylabel('K \otimes R (norm)')
title('"No gain control"')

subplot(3,3,7); hold on
plot(Ky*1e3)
plot(Kz_2*1e3)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

subplot(3,3,8); hold on
plot(filtertime,K2,'k')
xlabel('Lag (s)')
ylabel('Filter amplitude (a.u.)')
title('Reconstructed filters (R \rightarrow S)')
set(gca,'XLim',[-.6 .2])

subplot(3,3,9); hold on
scatter(S,S2,20,c,'filled')
set(gca,'XScale','log')
legend(['r^2 = ' oval(rsquare(S,S2))],'Location','northwest')
set(gca,'XTick',[1e-2 1e-1 1 10],'XLim',[1e-3 10])
xlabel('Stimulus (V)')
ylabel('K \otimes R (norm)')
title('"NL model fit to LN model"')

prettyFig('fs',15)

labelFigure

if being_published	
	snapnow	
	delete(gcf)
end

%% Sparse naturalistic stimuli: ab3A responses
% Now I repeat this analysis, but on the real neuron's data. It looks like the input nonlinearity is changing (b), but based on my previous analysis with synthetic data, this result is consistent both with there being "true" gain control and the existence of an output nonlinearity. 


% treat t the stimulus and the response as each other, and flip time
K0 = fitFilter2Data(fA,S,'reg',1,'filter_length',1e3,'offset',600);
filtertime = 1e-3*(1:length(K0)) - .6;
S0 = convolve(time,fA,K0,filtertime)/max(R0);

figure('outerposition',[0 0 1001 502],'PaperUnits','points','PaperSize',[1001 502]); hold on
subplot(1,2,1); hold on
plot(filtertime,K0,'k')
xlabel('Lag (s)')
ylabel('Filter amplitude (a.u.)')
title('Reconstructed filters (R \rightarrow S)')
set(gca,'XLim',[-.6 .2])

subplot(1,2,2); hold on
scatter(S,S0,20,c,'filled')
title('Reconstructed input NL')
set(gca,'XScale','log')
legend(['r^2 = ' oval(rsquare(S,S0))],'Location','northwest')
set(gca,'XTick',[1e-2 1e-1 1 10],'XLim',[1e-3 10])
xlabel('Stimulus (V)')
ylabel('K \otimes R (norm)')

prettyFig()

labelFigure

if being_published	
	snapnow	
	delete(gcf)
end


%% Version Info
%
pFooter;


