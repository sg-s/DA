

pHeader;

%% Reverse Filter analysis
% In this document, I assume NL-type models underlie data that we have, and attempt to a) recover this input nonlinearity non-parametrically and b) check if this input nonlinearity changes with stimulus condition or time. The way I do this is to first extract a filter from the response to the stimulus (a-causally), and then to plot the stimulus vs. projected response. 

   ;;;;;;  ;;;;;;;;     ;;;    ;;;;;;;;   ;;;;;;  ;;;;;;;; 
  ;;    ;; ;;     ;;   ;; ;;   ;;     ;; ;;    ;; ;;       
  ;;       ;;     ;;  ;;   ;;  ;;     ;; ;;       ;;       
   ;;;;;;  ;;;;;;;;  ;;     ;; ;;;;;;;;   ;;;;;;  ;;;;;;   
        ;; ;;        ;;;;;;;;; ;;   ;;         ;; ;;       
  ;;    ;; ;;        ;;     ;; ;;    ;;  ;;    ;; ;;       
   ;;;;;;  ;;        ;;     ;; ;;     ;;  ;;;;;;  ;;;;;;;; 

  ;;    ;;    ;;;    ;;;;;;;;     ;;;;;;  ;;;;;;;; ;;;; ;;     ;; 
  ;;;   ;;   ;; ;;      ;;       ;;    ;;    ;;     ;;  ;;;   ;;; 
  ;;;;  ;;  ;;   ;;     ;;       ;;          ;;     ;;  ;;;; ;;;; 
  ;; ;; ;; ;;     ;;    ;;        ;;;;;;     ;;     ;;  ;; ;;; ;; 
  ;;  ;;;; ;;;;;;;;;    ;;             ;;    ;;     ;;  ;;     ;; 
  ;;   ;;; ;;     ;;    ;;       ;;    ;;    ;;     ;;  ;;     ;; 
  ;;    ;; ;;     ;;    ;;        ;;;;;;     ;;    ;;;; ;;     ;; 


%% Sparse naturalistic stimulus: validation with DA model
% First, I validate this analysis method using synthetic data from a DA model. In the following figure, I use three different DA models run on the sparse naturalistic stimulus in Fig 2 of the paper:

%%
% 
% ; A DA model fit to the naturalistic stimulus data (first row) 
% ; The same DA model, but with gain control turned off (by setting B := 0) (second row)
% ; The same model as in the first row, but forcing the $K_z$ and $K_y$ filters to be the same (third row). This effective transforms the DA model into a LN model. 

%%
% In each row, the first column shows the parameters (filters) of the DA model I used to generate the synthetic data. The second column shows the reconstructed filters (from the response to the stimulus). Note that in all cases, most of the filter is a-causal (negative time is in the future). In the third column, I'm plotting the convolution of the filter with the response generated by the DA model vs. the stimulus. This is the reconstructed input nonlinearity. I'm colouring the points by the mean stimulus in the preceding 300ms (log-weighted). In (c), estimated stimulus correlates poorly with the stimulus. Is this because of the fast gain control or is it because of the inherent nonlinearity involved in the DA model? Let's see: In (f), where there is no gain control (by construction), the estimated stimulus correlates well with the stimulus. However, in (i), where there is also no gain control, but where I am fitting a NL model to LN model responses, we see apparent movement of the input nonlinearity. 

%%
% (c) looks very similar to (i). I can't tell these two apart. So it's hard to distinguish "true gain control" from a LN model using this approach. (What is not shown is that it is also hard to distinguish true gain control from a NL model by fitting models to the data). 


% get the first nat. stim
load(getPath(dataManager,'5c7dacc5b42ff0eebb980d80fec120c3'),'data','spikes')
PID = data(2).PID;
fA = spiketimes2f(spikes(2).A,1e-4*(1:length(PID)));
fA = mean(fA,2);
PID = PID(:,1:10:end)';
PID = PID - min(min(PID(1:5e3,:)));
S = mean(PID,2);
time = 1e-3*(1:length(S));

% fit a DA model to this
clear p
p.   s0 = 0;
p.  n_z = 2;
p.tau_z = 147.3750;
p.  n_y = 2;
p.tau_y = 27.2500;
p.    C = 0.5000;
p.    A = 170.4375;
p.    B = 2.7656;

[R0,~,~,Ky,Kz] = DAModelv2(S,p);

% now generate another set of responses with the dynamical adaptation turned off
p.B = 0;
R1 = DAModelv2(S,p);

% and another one which is effectively a LN model
p.B = 2.7656;
p.C = 1;
[R2,~,~,~,Kz_2] = DAModelv2(S,p);

% treat t the stimulus and the response as each other, and flip time
K0 = fitFilter2Data(R0,S,'reg',1,'filter_length',1e3,'offset',600);
filtertime = 1e-3*(1:length(K0)) - .6;
S0 = convolve(time,R0,K0,filtertime)/max(R0);

K1 = fitFilter2Data(R1,S,'reg',1,'filter_length',1e3,'offset',600);
S1 = convolve(time,R1,K1,filtertime)/max(R1);

K2 = fitFilter2Data(R2,S,'reg',1,'filter_length',1e3,'offset',600);
S2 = convolve(time,R2,K2,filtertime)/max(R2);

history_length = 300;

figure('outerposition',[0 0 910 902],'PaperUnits','points','PaperSize',[910 902]); hold on
subplot(3,3,1); hold on
plot(Ky*1e3)
plot(Kz*1e3)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

subplot(3,3,2); hold on
plot(filtertime,K0,'k')
xlabel('Lag (s)')
ylabel('Filter amplitude (a.u.)')
title('Reconstructed filters (R \rightarrow S)')
set(gca,'XLim',[-.6 .2])

subplot(3,3,3); hold on
shat = computeSmoothedStimulus(S,history_length);
shat = shat-min(shat);
shat = log(1+shat);
shat = shat/max(shat);
shat = 1 + ceil(shat*99);
shat(isnan(shat)) = 1;
cc = parula(100);
c = cc(shat,:);
scatter(S,S0,20,c,'filled')
set(gca,'XScale','log')
legend(['r^2 = ' oval(rsquare(S,S0))],'Location','northwest')
set(gca,'XTick',[1e-2 1e-1 1 10],'XLim',[1e-3 10])
xlabel('Stimulus (V)')
ylabel('K \otimes R (norm)')
title('"True gain control"')

subplot(3,3,4); hold on
plot(Ky*1e3)
plot(Kz*0)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

subplot(3,3,5); hold on
plot(filtertime,K1,'k')
xlabel('Lag (s)')
ylabel('Filter amplitude (a.u.)')
title('Reconstructed filters (R \rightarrow S)')
set(gca,'XLim',[-.6 .2])

subplot(3,3,6); hold on
scatter(S,S1,20,c,'filled')
set(gca,'XScale','log')
legend(['r^2 = ' oval(rsquare(S,S1))],'Location','northwest')
set(gca,'XTick',[1e-2 1e-1 1 10],'XLim',[1e-3 10])
xlabel('Stimulus (V)')
ylabel('K \otimes R (norm)')
title('"No gain control"')

subplot(3,3,7); hold on
plot(Ky*1e3)
plot(Kz_2*1e3)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

subplot(3,3,8); hold on
plot(filtertime,K2,'k')
xlabel('Lag (s)')
ylabel('Filter amplitude (a.u.)')
title('Reconstructed filters (R \rightarrow S)')
set(gca,'XLim',[-.6 .2])

subplot(3,3,9); hold on
scatter(S,S2,20,c,'filled')
set(gca,'XScale','log')
legend(['r^2 = ' oval(rsquare(S,S2))],'Location','northwest')
set(gca,'XTick',[1e-2 1e-1 1 10],'XLim',[1e-3 10])
xlabel('Stimulus (V)')
ylabel('K \otimes R (norm)')
title('"NL model fit to LN model"')

prettyFig('fs',15)

labelFigure

if being_published	
	snapnow	
	delete(gcf)
end

%% Sparse naturalistic stimuli: ab3A firing responses
% Now I repeat this analysis, but on the firing responses from ab3A. It looks like the input nonlinearity is changing (b), but based on my previous analysis with synthetic data, this result is consistent both with there being "true" gain control and the existence of an output nonlinearity. 


% treat t the stimulus and the response as each other, and flip time
K0 = fitFilter2Data(fA,S,'reg',1,'filter_length',1e3,'offset',600);
filtertime = 1e-3*(1:length(K0)) - .6;
S0 = convolve(time,fA,K0,filtertime)/max(R0);

figure('outerposition',[0 0 1001 502],'PaperUnits','points','PaperSize',[1001 502]); hold on
subplot(1,2,1); hold on
plot(filtertime,K0,'k')
xlabel('Lag (s)')
ylabel('Filter amplitude (a.u.)')
title('Reconstructed filters (R \rightarrow S)')
set(gca,'XLim',[-.6 .2])

subplot(1,2,2); hold on
scatter(S,S0,20,c,'filled')
title('Reconstructed input NL')
set(gca,'XScale','log')
legend(['r^2 = ' oval(rsquare(S,S0))],'Location','northwest')
set(gca,'XTick',[1e-2 1e-1 1 10],'XLim',[1e-3 10])
xlabel('Stimulus (V)')
ylabel('K \otimes R (norm)')

prettyFig()

labelFigure

if being_published	
	snapnow	
	delete(gcf)
end


%% Sparse naturalistic stimuli: ab3A LFP responses
% Now I repeat this analysis, but on the LFP responses from ab3A. I do this for the four ab3A neurons we recorded from, and plot the reconstructed nonlinearities, colouring each point by the value of the mean stimulus in the preceding 300ms. 

% get this data
clearvars -except being_published
load('/local-data/DA-paper/data-for-paper/nat-stim/ab3A_nat_stim.ORNData','-mat')
od(1) = [];
for i = length(od):-1:1
	data(i).LFP = mean(od(i).LFP,2);
	data(i).stimulus = mean(od(i).stimulus,2);
end

% extract filters
time = 1e-3*(1:length(data(1).LFP));
if exist('.cache/rfa_sparse_lfp_filters.mat','file') ~= 2
	disp('Computing reverse filters...')
	for i = length(data):-1:1
		data(i).K = fitFilter2Data(data(i).LFP,data(i).stimulus,'reg',1,'filter_length',1e3,'offset',600);
		filtertime = 1e-3*(1:length(data(i).K)) - .6;
		data(i).Shat = convolve(time,data(i).LFP,data(i).K,filtertime);
	end
	save('.cache/rfa_sparse_lfp_filters.mat','data')
else
	load('.cache/rfa_sparse_lfp_filters.mat','data');
end

history_length = 300;

figure('outerposition',[0 0 902 801],'PaperUnits','points','PaperSize',[902 801]); hold on
for i = 1:length(data)
	subplot(2,2,i); hold on
	shat = computeSmoothedStimulus(data(i).stimulus,history_length);
	shat = shat-min(shat);
	shat = log(1+shat);
	shat = shat/max(shat);
	shat = 1 + ceil(shat*99);
	shat(isnan(shat)) = 1;
	cc = parula(100);
	c = cc(shat,:);
	scatter(data(i).stimulus,data(i).Shat,20,c,'filled')
	legend(['r^2 = ' oval(rsquare(data(i).stimulus,data(i).Shat))],'Location','southeast')
	xlabel('Stimulus (V)')
	ylabel('K \otimes R')
	title(['ORN #' oval(i)])
end

prettyFig();

if being_published
	snapnow
	delete(gcf)
end

%%
% It sure looks like the input nonlinearities are changing in this figure, but as my previous analysis shows with synthetic data, it is hard to distinguish this from a static output nonlinearity. 

;;;;;;;;  ;;;;;;;; ;;    ;;  ;;;;;;  ;;;;;;;; 
;;     ;; ;;       ;;;   ;; ;;    ;; ;;       
;;     ;; ;;       ;;;;  ;; ;;       ;;       
;;     ;; ;;;;;;   ;; ;; ;;  ;;;;;;  ;;;;;;   
;;     ;; ;;       ;;  ;;;;       ;; ;;       
;;     ;; ;;       ;;   ;;; ;;    ;; ;;       
;;;;;;;;  ;;;;;;;; ;;    ;;  ;;;;;;  ;;;;;;;; 

;;    ;;    ;;;    ;;;;;;;;     ;;;;;;  ;;;;;;;; ;;;; ;;     ;; 
;;;   ;;   ;; ;;      ;;       ;;    ;;    ;;     ;;  ;;;   ;;; 
;;;;  ;;  ;;   ;;     ;;       ;;          ;;     ;;  ;;;; ;;;; 
;; ;; ;; ;;     ;;    ;;        ;;;;;;     ;;     ;;  ;; ;;; ;; 
;;  ;;;; ;;;;;;;;;    ;;             ;;    ;;     ;;  ;;     ;; 
;;   ;;; ;;     ;;    ;;       ;;    ;;    ;;     ;;  ;;     ;; 
;;    ;; ;;     ;;    ;;        ;;;;;;     ;;    ;;;; ;;     ;; 


%% Dense naturalistic stimulus: validation with DA model 
% In this section, I use the dense naturalistic stimulus and DA model simulations to see if this stimulus allows me to distinguish true gain control from the effect of a front-end or back-end nonlinearity. 

% get this data
clearvars -except being_published
load('/local-data/DA-paper/data-for-paper/fig7/nat-stim-ab3/consolidated_data.mat')

for i = max(cached_data.orn):-1:1
	data(i).LFP = nanmean(cached_data.LFP(:,cached_data.orn==i),2);
	R = cached_data.fA(:,cached_data.orn==i);
	R(R==0) = NaN;
	data(i).fA = nanmean(R,2);
	data(i).stimulus = nanmean(cached_data.PID(:,cached_data.orn==i),2);
end

data(1) = [];

% remove baseline
for i = length(data):-1:1
	data(i).stimulus = data(i).stimulus - min(data(i).stimulus);
end

% fit a DA model to firing rate responses 
clear p
p.  s0  = 0;
p.  n_z =  3;
p.tau_z =  82;
p.  n_y =  3;
p.tau_y =  11.6543;
p.    C =  0.5969;
p.    A =  547.9375;
p.    B =  8.5371;

% generate responses using this model
for i = length(data):-1:1
	[data(i).DA_R,~,~,Ky,Kz] = DAModelv2(data(i).stimulus,p);
end

% extract filters
time = 1e-3*(1:length(data(1).DA_R));
for i = length(data):-1:1
	data(i).K = fitFilter2Data(data(i).DA_R,data(i).stimulus,'reg',1,'filter_length',1e3,'offset',600);
	filtertime = 1e-3*(1:length(data(i).K)) - .6;
	data(i).Shat = convolve(time,data(i).DA_R,data(i).K,filtertime);
end

history_length = 300;

figure('outerposition',[0 0 1001 801],'PaperUnits','points','PaperSize',[1001 801]); hold on

% show DA model filters
subplot(2,3,1); hold on
plot(Ky*1e3)
plot(Kz*1e3)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

for i = 1:length(data)
	subplot(2,3,i+1); hold on
	shat = computeSmoothedStimulus(data(i).stimulus,history_length);
	shat = shat-min(shat);
	shat = log(1+shat);
	shat = shat/max(shat);
	shat = 1 + ceil(shat*99);
	shat(isnan(shat)) = 1;
	cc = parula(100);
	c = cc(shat,:);
	scatter(data(i).stimulus,data(i).Shat,20,c,'filled')
	legend(['r^2 = ' oval(rsquare(data(i).stimulus,data(i).Shat))],'Location','southeast')
	xlabel('Stimulus (V)')
	ylabel('K \otimes R')
	title(['ORN #' oval(i)])
end

prettyFig();

if being_published
	snapnow
	delete(gcf)
end

%%
% Now, I repeat this analysis, but turn the gain control off and make the DA model into a LN model by setting $K_y = K_z$

p.C = 1;

% generate responses using this model
for i = length(data):-1:1
	[data(i).DA_R,~,~,Ky,Kz] = DAModelv2(data(i).stimulus,p);
end


% extract filters
time = 1e-3*(1:length(data(1).DA_R));
for i = length(data):-1:1
	data(i).K = fitFilter2Data(data(i).DA_R,data(i).stimulus,'reg',1,'filter_length',1e3,'offset',600);
	filtertime = 1e-3*(1:length(data(i).K)) - .6;
	data(i).Shat = convolve(time,data(i).DA_R,data(i).K,filtertime);
end

history_length = 300;

figure('outerposition',[0 0 1001 801],'PaperUnits','points','PaperSize',[1001 801]); hold on

% show DA model filters
subplot(2,3,1); hold on
plot(Ky*1e3)
plot(Kz*1e3)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

for i = 1:length(data)
	subplot(2,3,i+1); hold on
	shat = computeSmoothedStimulus(data(i).stimulus,history_length);
	shat = shat-min(shat);
	shat = log(1+shat);
	shat = shat/max(shat);
	shat = 1 + ceil(shat*99);
	shat(isnan(shat)) = 1;
	cc = parula(100);
	c = cc(shat,:);
	scatter(data(i).stimulus,data(i).Shat,20,c,'filled')
	legend(['r^2 = ' oval(rsquare(data(i).stimulus,data(i).Shat))],'Location','southeast')
	xlabel('Stimulus (V)')
	ylabel('K \otimes R')
	title(['ORN #' oval(i)])
end

prettyFig();

if being_published
	snapnow
	delete(gcf)
end

%% Dense naturalistic stimulus: ab3A firing responses
% Now I repeat this analysis, but on the firing responses from ab3A. I do this for the five ab3A neurons we recorded from. In the first plot, I plot the reconstructed filters from the response to the stimulus for each neuron. In the other panels, I plot the reconstructed input nonlinearities, colouring each point by the mean stimulus in the preceding 300ms. 

% extract filters
time = 1e-3*(1:length(data(1).fA));
for i = length(data):-1:1
	K = fitFilter2Data(data(i).fA(5e3:end),data(i).stimulus(5e3:end),'reg',1,'filter_length',1e3,'offset',600);
	K = K(100:end-101);
	data(i).K = K;
	filtertime = 1e-3*(1:length(data(i).K)) - .5;
	data(i).Shat = convolve(time,data(i).fA,data(i).K,filtertime);
end

history_length = 300;

figure('outerposition',[0 0 902 801],'PaperUnits','points','PaperSize',[902 801]); hold on
subplot(2,3,1); hold on
plot(filtertime,[data.K])
xlabel('Filter lag (s)')
ylabel('Filter amplitude (norm)')


for i = 1:length(data)
	subplot(2,3,i+1); hold on
	shat = computeSmoothedStimulus(data(i).stimulus,history_length);
	shat = shat-min(shat);
	shat = log(1+shat);
	shat = shat/max(shat);
	shat = 1 + ceil(shat*99);
	shat(isnan(shat)) = 1;
	cc = parula(100);
	c = cc(shat,:);
	scatter(data(i).stimulus,data(i).Shat,20,c,'filled')
	legend(['r^2 = ' oval(rsquare(data(i).stimulus,data(i).Shat))],'Location','southeast')
	xlabel('Stimulus (V)')
	ylabel('K \otimes R')
	title(['ORN #' oval(i)])
end

prettyFig();

if being_published
	snapnow
	delete(gcf)
end

%% Dense naturalistic stimulus: ab3A LFP responses
% Now I repeat this analysis, but on the LFP responses from ab3A. I do this for the four ab3A neurons we recorded from, and plot the reconstructed nonlinearities, colouring each point by the value of the mean stimulus in the preceding 300ms. 


% remove baseline from LFP
for i = length(data):-1:1
	data(i).LFP = data(i).LFP - mean(data(i).LFP(1:5e3));
end

% extract filters
time = 1e-3*(1:length(data(1).LFP));
for i = length(data):-1:1
	data(i).K = fitFilter2Data(data(i).LFP,data(i).stimulus,'reg',1,'filter_length',1e3,'offset',600);
end

filtertime = 1e-3*(1:length(data(i).K)) - .6;

for i = length(data):-1:1
	data(i).Shat = convolve(time,data(i).LFP,data(i).K,filtertime);
end

history_length = 300;

figure('outerposition',[0 0 902 801],'PaperUnits','points','PaperSize',[902 801]); hold on

subplot(2,3,1); hold on
plot(filtertime,[data.K])
xlabel('Filter lag (s)')
ylabel('Filter amplitude (norm)')


for i = 1:length(data)
	subplot(2,3,i+1); hold on
	shat = computeSmoothedStimulus(data(i).stimulus,history_length);
	shat = shat-min(shat);
	shat = log(1+shat);
	shat = shat/max(shat);
	shat = 1 + ceil(shat*99);
	shat(isnan(shat)) = 1;
	cc = parula(100);
	c = cc(shat,:);
	scatter(data(i).stimulus,data(i).Shat,20,c,'filled')
	legend(['r^2 = ' oval(rsquare(data(i).stimulus,data(i).Shat))],'Location','southeast')
	xlabel('Stimulus (V)')
	ylabel('K \otimes R')
	title(['ORN #' oval(i)])
end

prettyFig();

if being_published
	snapnow
	delete(gcf)
end


						;;     ;;  ;;;;;;   ;;;;;;   
						;;;   ;;; ;;    ;; ;;    ;;  
						;;;; ;;;; ;;       ;;        
						;; ;;; ;;  ;;;;;;  ;;   ;;;; 
						;;     ;;       ;; ;;    ;;  
						;;     ;; ;;    ;; ;;    ;;  
						;;     ;;  ;;;;;;   ;;;;;;   


%% Mean shifted Gaussians: validation with DA model
% In the following figure, I use a DA model fit to ab3A responses to generate synthetic data. The stimulus fed into the DA model is the Gaussian data in Fig 1 in the paper. The filters of the DA model are shown in (a). I then reconstruct filters from the response to the stimulus as before (b). I use that to reconstruct input nonlinearities for each trial, and colour them by mean stimulus (c). We see that the reconstructed input nonlinearity appears to move to the right with increasing mean stimulus. 

% get MSG data
clear MSGdata
MSGdata = consolidateData2(getPath(dataManager,'93ba5d68174e3df9f462a1fc48c581da'));
MSGdata = cleanMSGdata(MSGdata);

% get the DA model fit for this
clear p
p.   s0 = -0.1503;
p.  n_z = 2;
p.tau_z = 255.3750;
p.  n_y = 2;
p.tau_y = 20.0748;
p.    C = 0.2345;
p.    A = 2.8700e+03;
p.    B = 100;

% generate responses using the DA model
MSGdata.DA_R = NaN*MSGdata.fA;
for i = 1:length(MSGdata.paradigm)
	[MSGdata.DA_R(:,i),~,~,Ky,Kz] = DAModelv2(MSGdata.PID(:,i),p);
end

% extract reverse filters for each trial 
MSGdata.K = NaN(800,length(MSGdata.paradigm));
MSGdata.Shat = NaN*MSGdata.fA;
MSGdata.filtertime = 1e-3*(1:length(MSGdata.K)) - .5;
time = 1e-3*(1:length(MSGdata.PID));
hash = dataHash(MSGdata);
K = cache(hash);
if isempty(K)
	for i = 1:length(MSGdata.paradigm)
		textbar(i,length(MSGdata.paradigm))
		S = MSGdata.PID(35e3:55e3,i);
		R = MSGdata.DA_R(35e3:55e3,i);
		K = fitFilter2Data(R,S,'reg',1,'filter_length',1e3,'offset',600);
		K = K(100:end-101); K = K/norm(K);
		MSGdata.K(:,i) = K;
	end
	cache(hash,MSGdata.K)
else
	MSGdata.K = K;
end

for i = 1:length(MSGdata.paradigm)
	MSGdata.Shat(:,i) = convolve(time,MSGdata.DA_R(:,i),MSGdata.K(:,i),MSGdata.filtertime);
end

figure('outerposition',[0 0 1501 500],'PaperUnits','points','PaperSize',[1501 500]); hold on
subplot(1,3,1); hold on
plot(Ky*1e3)
plot(Kz*1e3)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

subplot(1,3,2); hold on
c = parula(max(MSGdata.paradigm)+1);
for i = 1:max(MSGdata.paradigm)
	plot(MSGdata.filtertime,MSGdata.K(:,MSGdata.paradigm == i),'Color',c(i,:))
end
xlabel('Filter lag (s)')
ylabel('Filter amplitude (norm)')
title('Reconstructed filters')

ax = subplot(1,3,3); hold on
c = parula(max(MSGdata.paradigm)+1);
for i = 1:max(MSGdata.paradigm)
	S = MSGdata.PID(35e3:55e3,MSGdata.paradigm == i);
	if i == 1
		S(:,5) = NaN; % outlier
	end
	Shat = MSGdata.Shat(35e3:55e3,MSGdata.paradigm == i);
	plotPieceWiseLinear(S(:),Shat(:),'Color',c(i,:),'nbins',30);
end
ax.YLim(1) = 0;
ax.XLim(1) = 0;
xlabel('Stimulus (V)')
ylabel('K \otimes R')

prettyFig();

labelFigure

if being_published
	snapnow
	delete(gcf)
end

%%
% Now, what if we repeat this analysis, but use a DA model with gain controlled turned off? Once again, I do this by setting $K_y = K_z$, so that the DA model effectively becomes a LN model. 

p.s0 = 0;
p.C = 1;

% generate responses using the DA model
MSGdata.DA_R = NaN*MSGdata.fA;
for i = 1:length(MSGdata.paradigm)
	[MSGdata.DA_R(:,i),~,~,Ky,Kz] = DAModelv2(MSGdata.PID(:,i),p);
end

% extract reverse filters for each trial 
MSGdata.K = NaN(800,length(MSGdata.paradigm));
MSGdata.Shat = NaN*MSGdata.fA;
MSGdata.filtertime = 1e-3*(1:length(MSGdata.K)) - .5;
time = 1e-3*(1:length(MSGdata.PID));
hash = dataHash(MSGdata);
K = cache(hash);
if isempty(K)
	for i = 1:length(MSGdata.paradigm)
		textbar(i,length(MSGdata.paradigm))
		S = MSGdata.PID(35e3:55e3,i);
		R = MSGdata.DA_R(35e3:55e3,i);
		K = fitFilter2Data(R,S,'reg',1,'filter_length',1e3,'offset',600);
		K = K(100:end-101); K = K/norm(K);
		MSGdata.K(:,i) = K;
	end
	cache(hash,MSGdata.K);
else
	MSGdata.K = K;
end

for i = 1:length(MSGdata.paradigm)
	MSGdata.Shat(:,i) = convolve(time,MSGdata.DA_R(:,i),MSGdata.K(:,i),MSGdata.filtertime);
end

figure('outerposition',[0 0 1501 500],'PaperUnits','points','PaperSize',[1501 500]); hold on
subplot(1,3,1); hold on
plot(Ky*1e3)
plot(Kz*1e3)
legend({'K_y','K_z'})
xlabel('Filter lag (ms)')
ylabel('Filter amplitude (a.u.)')
title('DA Model parameters')

subplot(1,3,2); hold on
c = parula(max(MSGdata.paradigm)+1);
for i = 1:max(MSGdata.paradigm)
	plot(MSGdata.filtertime,MSGdata.K(:,MSGdata.paradigm == i),'Color',c(i,:))
end
xlabel('Filter lag (s)')
ylabel('Filter amplitude (norm)')
title('Reconstructed filters')

ax = subplot(1,3,3); hold on
c = parula(max(MSGdata.paradigm)+1);
for i = 1:max(MSGdata.paradigm)
	S = MSGdata.PID(35e3:55e3,MSGdata.paradigm == i);
	if i == 1
		S(:,5) = NaN; % outlier
	end
	Shat = MSGdata.Shat(35e3:55e3,MSGdata.paradigm == i);
	plotPieceWiseLinear(S(:),Shat(:),'Color',c(i,:),'nbins',30);
end
ax.YLim(1) = 0;
ax.XLim(1) = 0;
xlabel('Stimulus (V)')
ylabel('K \otimes R')

prettyFig();
labelFigure

if being_published
	snapnow
	delete(gcf)
end

%% Mean Shifted Gaussians: ab3A firing rate
% Now, I repeat this analysis on the real data. 

% extract reverse filters for each trial 
MSGdata.K = NaN(800,length(MSGdata.paradigm));
MSGdata.Shat = NaN*MSGdata.fA;
MSGdata.filtertime = 1e-3*(1:length(MSGdata.K)) - .5;
time = 1e-3*(1:length(MSGdata.PID));
hash = dataHash(MSGdata);
K = cache(hash);
if isempty(K)
	for i = 1:length(MSGdata.paradigm)
		S = MSGdata.PID(35e3:55e3,i);
		R = MSGdata.fA(35e3:55e3,i);
		try
			K = fitFilter2Data(R,S,'reg',1,'filter_length',1e3,'offset',600);
			K = K(100:end-101); K = K/norm(K);
			MSGdata.K(:,i) = K;
		catch
		end
	end
	cache(hash,MSGdata.K);
else
	MSGdata.K = K;
end

for i = 1:length(MSGdata.paradigm)
	try
		MSGdata.Shat(:,i) = convolve(time,MSGdata.fA(:,i),MSGdata.K(:,i),MSGdata.filtertime);
	catch
	end
end

figure('outerposition',[0 0 1001 500],'PaperUnits','points','PaperSize',[1001 500]); hold on

subplot(1,2,1); hold on
c = parula(max(MSGdata.paradigm)+1);
for i = 1:max(MSGdata.paradigm)
	plot(MSGdata.filtertime,MSGdata.K(:,MSGdata.paradigm == i),'Color',c(i,:))
end
xlabel('Filter lag (s)')
ylabel('Filter amplitude (norm)')
title('Reconstructed filters')

ax = subplot(1,2,2); hold on
c = parula(max(MSGdata.paradigm)+1);
for i = 1:max(MSGdata.paradigm)
	S = MSGdata.PID(35e3:55e3,MSGdata.paradigm == i);
	if i == 1
		S(:,5) = NaN; % outlier
	end
	Shat = MSGdata.Shat(35e3:55e3,MSGdata.paradigm == i);
	plotPieceWiseLinear(S(:),Shat(:),'Color',c(i,:),'nbins',30);
end
ax.YLim(1) = 0;
ax.XLim(1) = 0;
xlabel('Stimulus (V)')
ylabel('K \otimes R')

prettyFig();
labelFigure

if being_published
	snapnow
	delete(gcf)
end

%%
% Unsurprisingly, filter estimation is hard as the mean stimulus increases. But I still see the basic effect: input nonlinearities still move to the right, meaning that this is "true gain control". 

%%
% What if I only use filters estimated from the lowest doses (where the responses and signal are cleanest)? Does that then help me estimate the input nonlinearities more cleanly? 

% extract reverse filters for each trial 
MSGdata.Shat = NaN*MSGdata.fA;

% use K only from the lowest paradigm
K = mean(MSGdata.K(:,MSGdata.paradigm==1),2);
for i = 1:length(MSGdata.paradigm)
	MSGdata.Shat(:,i) = convolve(time,MSGdata.fA(:,i),K,MSGdata.filtertime);
end

figure('outerposition',[0 0 500 500],'PaperUnits','points','PaperSize',[1001 500]); hold on

c = parula(max(MSGdata.paradigm)+1);
for i = 1:max(MSGdata.paradigm)
	S = MSGdata.PID(35e3:55e3,MSGdata.paradigm == i);
	if i == 1
		S(:,5) = NaN; % outlier
	end
	Shat = MSGdata.Shat(35e3:55e3,MSGdata.paradigm == i);
	plotPieceWiseLinear(S(:),Shat(:),'Color',c(i,:),'nbins',30);
end
xlabel('Stimulus (V)')
ylabel('K \otimes R')
title('Using a single filter')

prettyFig();


if being_published
	snapnow
	delete(gcf)
end

%% Kinetics of gain change
% In this section, I plot the nonlinearity at different time bins along the time trace to see how quickly the nonlinearity changes. In the following figure, each panel is the reconstructed input nonlinearity at a given mean stimulus. The colors indicate time since odor onset (see colorbar). The title specifies the mean stimulus for the panel. 

bin_starts = 5.5e3:500:20e3;
bin_ends = bin_starts + 2e3;
c = jet(length(bin_starts));

figure('outerposition',[0 0 1000 802],'PaperUnits','points','PaperSize',[1000 802]); hold on

subplot_counter = 1;

for i = [2 3 5  6 7 10]
	subplot(2,3,subplot_counter); hold on
	for j = 1:length(bin_starts)
		S = MSGdata.PID(bin_starts(j):bin_ends(j),MSGdata.paradigm == i);
		Shat = MSGdata.Shat(bin_starts(j):bin_ends(j),MSGdata.paradigm == i);
		plotPieceWiseLinear(S(:),Shat(:),'Color',c(j,:),'nbins',30);
	end
	colormap jet
	caxis([bin_starts(1)/1e3 bin_starts(end)/1e3] - 5)
	if subplot_counter == 1
		cb = colorbar;
		cb.Position = [.3 .6 .02 .1];
	end
	subplot_counter = subplot_counter + 1;
	xlabel('Stimulus (V)')
	ylabel('K \otimes R')
	title(['\mu_{Stimulus} = ' oval(mean(S(:))) 'V'])
end

prettyFig();

if being_published
	snapnow
	delete(gcf)
end


% To quantify these changes, I fit a Hill function to each curve, keeping the n fixed. 

% Kd = NaN*MSGdata.PID;

% ft = fittype('hillFit(x,A,k,n,x_offset)');

% for i = 1:max(MSGdata.paradigm)
% 	textbar(i,max(MSGdata.paradigm))
% 	for j = 1:length(bin_starts)

% 		temp1 = MSGdata.PID(bin_starts(j):bin_ends(j),MSGdata.paradigm == i);
% 		temp2 = MSGdata.Shat(bin_starts(j):bin_ends(j),MSGdata.paradigm == i);
		
% 		rm_this = isnan(temp2) | temp2 == 0;
% 		temp1(rm_this) = [];
% 		temp2(rm_this) = [];

% 		if max(temp2) > 0
% 			ff = fit(temp1(:),temp2(:),ft,'StartPoint',[max(temp2(:)) mean(temp1(:)) 1 0],'Upper',[max(temp2(:)) 10*max(temp1(:)) 1 0],'Lower',[0 0 1 0],'MaxIter',1e3);
% 			ii = floor((bin_starts(j) + bin_ends(j))/2);
% 			Kd(ii,i) = ff.k;
% 		end
% 	end
% end

% figure('outerposition',[0 0 1000 500],'PaperUnits','points','PaperSize',[1000 500]); hold on
% c = parula(max(MSGdata.paradigm)+1);
% for i = 1:max(MSGdata.paradigm)
% 	temp = Kd(:,i);
% 	ii = floor((bin_starts + bin_ends)/2);
% 	temp = temp(ii,:);
% 	plot(ii*1e-3,temp,'o','Color',c(i,:))
% end




%% Version Info
%
pFooter;


